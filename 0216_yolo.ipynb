{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7Trn4bEKvGUa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import PIL\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.layers import Input, Conv2D,BatchNormalization,LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate,Add\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array,array_to_img\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import numpy as np\n",
        "import struct\n",
        "import scipy.misc\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        '''\n",
        "        가중치 파일 원시 바이너리 형식으로 열고,\n",
        "        파일의 헤더 정보를 읽어 들임\n",
        "        '''\n",
        "        # major, minor, revision 파일의 버전\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major, = struct.unpack('i', w_f.read(4))\n",
        "            minor, = struct.unpack('i', w_f.read(4))\n",
        "            revision ,= struct.unpack('i', w_f.read(4))\n",
        "\n",
        "            # 파일 버전이 2 이상인 경우 두 개의 정수를 더 읽어들임\n",
        "\n",
        "            if (major * 10 + minor) >= 2 and major <1000 and minor <1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "\n",
        "            # major나 minor가 1000을 초과하면, transpose 를 True 로 설정\n",
        "            transpose = (major > 1000) or (minor > 1000)\n",
        "\n",
        "            binary = w_f.read()\n",
        "\n",
        "        # 현재 파일에서 읽고 있는 위치\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary , dtype='float32')\n",
        "\n",
        "\n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset - size : self.offset]\n",
        "\n",
        "    def load_weight(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                # 'conv_{i}' 레이어 찾기\n",
        "                conv_layer = model.get_layer(f'conv_{str(i)}')\n",
        "                # batchnorm 정규화 가중치 로드 (잠시후 에)\n",
        "                if i not in [1,11,111]:\n",
        "                    norm_layer = model.get_layer(f'bnorm_{str(i)}')\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\n",
        "                    beta = self.read_bytes(size) # 편향\n",
        "                    gamma = self.read_bytes(size) # 스케일\n",
        "                    mean = self.read_bytes(size) # 평균\n",
        "                    var = self.read_bytes(size) # 분산\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
        "\n",
        "                if len(conv_layer.get_weights())>1:\n",
        "                    bias = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape)) # 편향 값 가중\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape)) # 커널 값 가중치\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))#\n",
        "                    kernel = kernel.transpose([2,3,1,0]) # 가중치 transpose, custom transpose를 취함\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape)) # 커널 값 가중치\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))#\n",
        "                    kernel = kernel.transpose([2,3,1,0]) # 가중치 transpose, custom transpose를 취함\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                print(f'{str(i)} 해당 위치에 레이어가 없습니다')\n",
        "    def reset(self):\n",
        "        self.offset = 0"
      ],
      "metadata": {
        "id": "oY6qugLr00k1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "    for conv in convs:\n",
        "        # 블록 내 마지막 -1 번째 레이어가 skip 연결이 되어 있다면\n",
        "        # 그 위치를 저장\n",
        "        if count == (len(convs) -2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "        # 다크넷은 패딩을 위쪽과 왼쪽에 선호 하기 때문에\n",
        "        # stride가 1보다 큰 경우 위, 왼쪽에만 패딩을 씌움\n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0), (1,0)))(x)\n",
        "        x = Conv2D(conv['filter'], conv['kernel'],\n",
        "                   strides=conv['stride'],\n",
        "                   padding = 'valid' if conv['stride'] > 1 else 'same',\n",
        "                   name = 'conv_'+str(conv['layer_idx']),\n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "\n",
        "        #배치 정규화를 수행하는 레이어\n",
        "        if conv['bnorm'] :\n",
        "            x = BatchNormalization(epsilon=0.001, name='bnorm_'+str(conv['layer_idx']))(x)\n",
        "        # 활성화 함수로 leaky_relu를 사용 하는 경우\n",
        "        if conv['leaky'] :\n",
        "            x = LeakyReLU(alpha=0.1 , name='leaky_'+str(conv['layer_idx']))(x)\n",
        "    # skip 연결이 활성화가 되어 있다면 해당 위치의 텐서와 현재 텐서를 더한다.\n",
        "    return Add()([skip_connection,x]) if skip else x\n",
        "\n"
      ],
      "metadata": {
        "id": "oiZhNxFm3LsB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "\n",
        "    #0 ~ 4\n",
        "    x = _conv_block(input_image,[{'filter':32, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':0},\n",
        "                                 {'filter':64, 'kernel' : 3, 'stride' : 2, 'bnorm':True, 'leaky':True, 'layer_idx':1},\n",
        "                                 {'filter':32, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':2},\n",
        "                                 {'filter':64, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':3}])\n",
        "    # 5 ~ 8\n",
        "    x = _conv_block(x ,[{'filter':128, 'kernel' : 3, 'stride' : 2, 'bnorm':True, 'leaky':True, 'layer_idx':5},\n",
        "                        {'filter':64, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':6},\n",
        "                        {'filter':128, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':7}])\n",
        "    # 9 ~ 11\n",
        "    x = _conv_block(x ,[{'filter':64, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':9},\n",
        "                        {'filter':128, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':10}])\n",
        "    # 12 ~ 15\n",
        "    x = _conv_block(x ,[{'filter':256, 'kernel' : 3, 'stride' : 2, 'bnorm':True, 'leaky':True, 'layer_idx':12},\n",
        "                        {'filter':128, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':13},\n",
        "                        {'filter':256, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':14}])\n",
        "    # 16 ~ 36\n",
        "    for i in range(7):\n",
        "        #16 17 19 20 22 23 24 25\n",
        "        x = _conv_block(x,[{'filter':128, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':16 + i * 3},\n",
        "                        {'filter':256, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':17 + i * 3}])\n",
        "    skip_36 = x\n",
        "\n",
        "    # 37~40\n",
        "    x = _conv_block(x ,[{'filter':512, 'kernel' : 3, 'stride' : 2, 'bnorm':True, 'leaky':True, 'layer_idx':37},\n",
        "                        {'filter':256, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':38},\n",
        "                        {'filter':512, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':39}])\n",
        "\n",
        "    # 41 ~ 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x,[{'filter':256, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':41 + i * 3},\n",
        "                        {'filter':512, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':42 + i * 3}])\n",
        "    skip_61 = x\n",
        "    # 62~ 65\n",
        "    x = _conv_block(x ,[{'filter':1024, 'kernel' : 3, 'stride' : 2, 'bnorm':True, 'leaky':True, 'layer_idx':62},\n",
        "                        {'filter':512, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':63},\n",
        "                        {'filter':1024, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':64}])\n",
        "    # 66 ~74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x,[{'filter':512, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':66 + i * 3},\n",
        "                        {'filter':1024, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':67 + i * 3}])\n",
        "    # 75 ~ 79\n",
        "    x = _conv_block(x ,[{'filter':512, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':75},\n",
        "                        {'filter':1024, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':76},\n",
        "                        {'filter':512, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':77},\n",
        "                        {'filter':1024, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':78},\n",
        "                        {'filter':512, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':79}], skip=False)\n",
        "\n",
        "    yolo_82 = _conv_block(x ,[{'filter':1024, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':80},\n",
        "                        {'filter':255, 'kernel' : 1, 'stride' : 1, 'bnorm':False, 'leaky':False, 'layer_idx':81}], skip=False)\n",
        "    #\n",
        "    x  =  _conv_block(x ,[{'filter':256, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "\n",
        "    #87 ~ 91\n",
        "    x = _conv_block(x ,[{'filter':256, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':87},\n",
        "                        {'filter':512, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':88},\n",
        "                        {'filter':256, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':89},\n",
        "                        {'filter':512, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':90},\n",
        "                        {'filter':256, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':91}],skip=False)\n",
        "\n",
        "    # 92 ~ 94\n",
        "    yolo_94 = _conv_block(x ,[{'filter':512, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':92},\n",
        "                        {'filter':255, 'kernel' : 1, 'stride' : 1, 'bnorm':False, 'leaky':False, 'layer_idx':93}],skip=False)\n",
        "\n",
        "    x =  _conv_block(x ,[{'filter':128, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "\n",
        "    # 99 ~ 106\n",
        "    yolo_106 = _conv_block(x ,[{'filter':128, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':99},\n",
        "                        {'filter':256, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':100},\n",
        "                        {'filter':128, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':101},\n",
        "                        {'filter':256, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':102},\n",
        "                        {'filter':128, 'kernel' : 1, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':103},\n",
        "                        {'filter':256, 'kernel' : 3, 'stride' : 1, 'bnorm':True, 'leaky':True, 'layer_idx':104},\n",
        "                        {'filter':255, 'kernel' : 1, 'stride' : 1, 'bnorm':False, 'leaky':False, 'layer_idx':105}],skip=False)\n",
        "\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
        "    return model"
      ],
      "metadata": {
        "id": "TmcoUOk-nZzX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# yolo v3 모델 정의하기\n",
        "yolov3 = make_yolov3_model()\n",
        "yolov3.summary()"
      ],
      "metadata": {
        "id": "BuhepqXN2RVa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/yolo.zip"
      ],
      "metadata": {
        "id": "gTcvgKP42SQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_reader = WeightReader('/content/yolov3.weights')"
      ],
      "metadata": {
        "id": "TARmbvtC2XEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_reader.load_weight(yolov3)\n",
        "yolov3.save('model.tf')"
      ],
      "metadata": {
        "id": "BCjg7OGn4Nz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시그모이드 함수\n",
        "def _sigmoid(x):\n",
        "    return 1./(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "bOxYF4Sf8vDp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 바운딩박스 세팅 클래스\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes=None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        # objness = 오브젝트 일 확률\n",
        "        self.objness = objness\n",
        "        # classes = 오브젝트가 어떤 클래스일지 확률\n",
        "        self.classes = classes\n",
        "        # 초기 레이블과 점수는 -1\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        # 레이블이 아직 설정되지 않았다면, 가장 높은 점수의 클래스를 레이블로 설정\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        # 점수가 아직 설정되지 않았다면, 레이블 클래스 확률을 점수로 설정\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "        return self.score"
      ],
      "metadata": {
        "id": "u9QlP_g386Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "네트 워크 출력을 디코딩 하는 함수\n",
        "각 출력박스를 바운드 박스 객체로 변환\n",
        "네트워크 출력, 앵커, 객체 입력값, 네트워크 높이 및 네트워크의 너비를 매개변수로 받는다.\n",
        "출력은 바운딩 박스의 리스트,  각 x,y좌표, 객체일 확률, 클래스 확률값들이 나옴\n",
        "'''\n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "    grid_h,grid_w = netout.shape[:2]\n",
        "    nb_box = 3\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "    boxes = []\n",
        "    netout[... , :2] = _sigmoid(netout[... :2])\n",
        "    # ...은 모든 그리드 셀을 의미, 0~1 depth 는 xy 0~1 normalize\n",
        "    netout[... , 2:4] = _sigmoid(netout[... ,2:4])\n",
        "    # ...은 모든 그리드 셀을 의미, 0~1 depth 는 wh 0~1 normalize\n",
        "    netout[... , 5:] = netout[... , 4][... , np.newaxis] * netout[... , 5:]\n",
        "    # objtness score * class probabilty\n",
        "    netout[... , 5:] *= netout[... , 5:] > obj_thresh\n",
        "    # 위 곱한값이 objthsh를 못넘으면 0으로 만듬\n",
        "\n",
        "    for i in range(grid_h * grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "        for b in range(nb_box):\n",
        "            # 4번째 요소는 objectness 점수\n",
        "            objectness = netout[int(row)][int[col]][b][4]\n",
        "            # objectness가 임계값 보다 낮으면 해당 박스는 애초에 무시한다.\n",
        "            if(objectness.all() < obj_thresh):continue\n",
        "            # 처음 4개 요소는 x,y,w,h\n",
        "            x,y,w,h = netout[int(row)][int[col]][b][:4]\n",
        "            x = (col + x) / grid_w # yolo는 바운딩 박스의 좌상단 좌표가 아닌, 중앙값 기준\n",
        "            y = (row + y) / grid_h # 중심위치, 단위: 이미지 높이\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h\n",
        "\n",
        "            # 마지막 요소들은 클래스 확률 입니다.\n",
        "            classes = netout[int(row)][int(col)][b][5:]\n",
        "            box = BoundBox(x,y,w,h,objectness, classes)\n",
        "            boxes.append(box)\n",
        "    return boxes\n"
      ],
      "metadata": {
        "id": "A7pgSbzW_57K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}